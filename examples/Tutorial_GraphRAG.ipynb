{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üåç GraphRAG Core: Climate Intelligence Tutorial\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nunezmatias/grafoRag/blob/main/examples/Tutorial_GraphRAG.ipynb)\n",
                "\n",
                "Welcome to the **GraphRAG Core** tutorial. This notebook demonstrates a next-generation retrieval system designed for scientific discovery.\n",
                "\n",
                "By combining vector search with a causal knowledge graph, we can answer complex questions about climate adaptation, identifying not just *what* is happening, but *why* it matters and what ripple effects it might trigger."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Installation\n",
                "Install the library directly from GitHub. This will setup the engine and download required dependencies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install git+https://github.com/nunezmatias/grafoRag.git\n",
                "!pip install -q -U google-genai\n",
                "\n",
                "import os\n",
                "from graphrag_core import GraphRAGEngine\n",
                "print('‚úÖ Libraries Installed & Loaded')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Initialize the Engine\n",
                "Initializing the engine is simple. If the climate data is not found locally, it will be automatically downloaded from the cloud storage."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "engine = GraphRAGEngine()\n",
                "# Output should say: \"Attempting to download from Google Drive...\" followed by \"System Ready\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run a Deep Research Query\n",
                "We will now perform a complex search. The engine allows you to tune the depth of the investigation:\n",
                "\n",
                "- **`top_k`** estabelece la amplitud tem√°tica.\n",
                "- **`context_k`** controla la profundidad de evidencia por tema.\n",
                "- **`hops`** define el razonamiento causal."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define your research question\n",
                "query = \"cascading risks of extreme heat and urban floods\"\n",
                "\n",
                "# Execute the Search\n",
                "results = engine.search(\n",
                "    query=query, \n",
                "    top_k=2, \n",
                "    context_k=4, \n",
                "    hops=2\n",
                ")\n",
                "\n",
                "print(f\"--- Research Stats ---\")\n",
                "print(f\"Primary Sources: {results['stats']['primary']}\")\n",
                "print(f\"Context Expansion: {results['stats']['context']}\")\n",
                "print(f\"Causal Links:      {results['stats']['graph']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Inspect the Intelligence\n",
                "Verify the quality of the retrieved data before generating the final answer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Check the Top Paper\n",
                "if results['papers']:\n",
                "    p = results['papers'][0]\n",
                "    print(f\"üìÑ Top Paper: {p['title']}\")\n",
                "    print(f\"   Snippet: {p['content'][:200]}...\")\n",
                "\n",
                "# 2. Check Discovered Causal Chains\n",
                "if results['graph_links']:\n",
                "    print(\"\")\n",
                "    print(\"üîó Sample Causal Chains:\")\n",
                "    for link in results['graph_links'][:5]:\n",
                "        print(f\"   {link['node1']} --[{link['relation']}]--> {link['node2']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Construct the Expert Prompt\n",
                "We package the data into a rigorous prompt for the LLM using the engine's built-in template."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "prompt = engine.format_prompt(results, query)\n",
                "\n",
                "print(\"Here is your optimized prompt (COPY THIS):\")\n",
                "print(\"--------------------------------------------------\")\n",
                "print(prompt)\n",
                "print(\"--------------------------------------------------\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Generate Answer with Gemini Flash ‚ö°\n",
                "Send the prompt to Google's Gemini Flash model for final synthesis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google import genai\n",
                "from google.colab import userdata\n",
                "from IPython.display import Markdown, display\n",
                "\n",
                "try:\n",
                "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
                "    client = genai.Client(api_key=GOOGLE_API_KEY)\n",
                "    print(\"‚úÖ Gemini Client Configured\")\n",
                "except Exception as e:\n",
                "    print(\"‚ö†Ô∏è Error: API Key not found. Please add 'GOOGLE_API_KEY' to Colab Secrets.\")\n",
                "\n",
                "print(\"‚è≥ Generating expert response with Gemini Flash...\")\n",
                "try:\n",
                "    response = client.models.generate_content(\n",
                "        model='gemini-flash-latest',\n",
                "        contents=prompt\n",
                "    )\n",
                "    display(Markdown(\"### ü§ñ Response:\"))\n",
                "    display(Markdown(response.text))\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå Generation Error: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Advanced: Custom Prompt Template\n",
                "Access raw variables and customize the output structure easily."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# OPTION 1: Quick Customization (Role & Instructions only)\n",
                "# Override default persona without changing the structure.\n",
                "prompt_editor = engine.format_prompt(\n",
                "    results, \n",
                "    query,\n",
                "    role=\"You are a Scientific Editor for Nature.\",\n",
                "    instructions=\"Summarize key findings in 1 paragraph for a general audience.\"\n",
                ")\n",
                "print(\"--- Quick Edit Prompt ---\")\n",
                "print(prompt_editor[:300] + \"...\\n\")\n",
                "\n",
                "# OPTION 2: Full Layout Control (Custom Template)\n",
                "# Use markers {role}, {query}, {papers_block}, {graph_block}, {instructions} to redesign the prompt.\n",
                "my_template = \"\"\"# INVESTIGATION REPORT\n",
                "Target: {query}\n",
                "Researcher: {role}\n",
                "\n",
                "EVIDENCE FOUND:\n",
                "{papers_block}\n",
                "{graph_block}\n",
                "\n",
                "ACTION REQUIRED:\n",
                "{instructions}\n",
                "\"\"\"\n",
                "\n",
                "prompt_custom = engine.format_prompt(\n",
                "    results, \n",
                "    query,\n",
                "    role=\"Senior Analyst\",\n",
                "    template=my_template,\n",
                "    instructions=\"List top 3 risks identified.\"\n",
                ")\n",
                "print(\"--- Fully Custom Prompt ---\")\n",
                "print(prompt_custom[:300] + \"...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Bonus: Swap the Brain üß†\n",
                "Download and load a new domain dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Download and Extract the New Brain\n",
                "!wget -q https://github.com/nunezmatias/grafoRag/raw/main/examples/test_brain.zip\n",
                "!unzip -o -q test_brain.zip\n",
                "\n",
                "# 2. Initialize the Engine with the New Data\n",
                "local_engine = GraphRAGEngine(\n",
                "    vector_db_path='./test_brain/test_db', \n",
                "    graph_json_path='./test_brain/test_skeleton.json'\n",
                ")\n",
                "\n",
                "# 3. Validation Search: \"Effects of heat waves on health\"\n",
                "# This tests if the brain contains relevant knowledge on the topic.\n",
                "query_test = \"Effects of heat waves on health\"\n",
                "results_local = local_engine.search(query_test, top_k=2)\n",
                "\n",
                "# 4. Show Stats\n",
                "print(f\"--- Local Brain Stats for '{query_test}' ---\")\n",
                "print(f\"Primary Sources: {results_local['stats']['primary']}\")\n",
                "print(f\"Propagated Links:  {results_local['stats']['graph']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Advanced: Load from Google Drive ‚òÅÔ∏è\n",
                "Share custom knowledge bases via Drive File IDs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Load Brain from Google Drive (Cloud)\n",
                "# Only works if you have permission or the ID is public.\n",
                "MY_CUSTOM_GDRIVE_ID = \"1iKcEzECN9LTMi3bIq4ocRfFJgvb1dLus\"\n",
                "\n",
                "try:\n",
                "    print(f\"‚òÅÔ∏è Downloading Brain ID: {MY_CUSTOM_GDRIVE_ID}...\")\n",
                "    cloud_engine = GraphRAGEngine(gdrive_id=MY_CUSTOM_GDRIVE_ID)\n",
                "    print(\"‚úÖ Custom Brain Loaded Successfully\")\n",
                "    \n",
                "    # 2. Validation Search on the Same Topic\n",
                "    query_cloud = \"Effects of heat waves on health\"\n",
                "    results_cloud = cloud_engine.search(query_cloud, top_k=2)\n",
                "\n",
                "    # 3. Compare Stats\n",
                "    print(f\"\\n--- Cloud Brain Stats for '{query_cloud}' ---\")\n",
                "    print(f\"Primary Sources: {results_cloud['stats']['primary']}\")\n",
                "    print(f\"Propagated Links:  {results_cloud['stats']['graph']}\")\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå Error loading from Drive: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}