{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Core: Climate Intelligence Tutorial\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nunezmatias/grafoRag/blob/main/examples/Tutorial_GraphRAG.ipynb)\n",
    "\n",
    "Welcome to the GraphRAG Core interactive research tool. This system bridges the gap between unstructured scientific literature and structured causal knowledge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/nunezmatias/grafoRag.git\n",
    "!pip install -q -U google-genai\n",
    "\n",
    "import os\n",
    "from graphrag_core import GraphRAGEngine\n",
    "print('Libraries Installed & Loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = GraphRAGEngine()\n",
    "# System will download data if missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run a Deep Research Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your research question\n",
    "query = \"cascading risks of extreme heat and urban floods\"\n",
    "\n",
    "# Execute the Search\n",
    "results = engine.search(\n",
    "    query=query, \n",
    "    top_k=3, \n",
    "    context_k=4, \n",
    "    hops=2\n",
    ")\n",
    "\n",
    "print(\"--- Research Stats ---\")\n",
    "print(f\"Primary Sources: {results[\"stats\"][\"primary\"]}\")\n",
    "print(f\"Context Expansion: {results[\"stats\"][\"context\"]}\")\n",
    "print(f\"Causal Links:      {results[\"stats\"][\"graph\"]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect the Intelligence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check the Top Paper\n",
    "if results['papers']:\n",
    "    p = results['papers'][0]\n",
    "    title = p['title']\n",
    "    content = p['content'][:200]\n",
    "    print(f'Top Paper: {title}')\n",
    "    print(f'Snippet: {content}...')\n",
    "\n",
    "# 2. Check Discovered Causal Chains\n",
    "if results['graph_links']:\n",
    "    print('\nSample Causal Chains:')\n",
    "    for link in results['graph_links'][:5]:\n",
    "        n1 = link['node1']\n",
    "        n2 = link['node2']\n",
    "        rel = link['relation']\n",
    "        print(f'   {n1} --[{rel}]--> {n2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Construct the Expert Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = engine.format_prompt(results, query)\n",
    "print('Prompt ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Answer with Gemini Flash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.colab import userdata\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "try:\n",
    "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "    client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "    print('Gemini Client Configured')\n",
    "except Exception as e:\n",
    "    print('Error: API Key not found.')\n",
    "\n",
    "print('Generating response...')\n",
    "try:\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-flash-latest',\n",
    "        contents=prompt\n",
    "    )\n",
    "    display(Markdown('### Response:'))\n",
    "    display(Markdown(response.text))\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced: Build Your Own Prompt Template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_role = \"You are a Data Journalist.\"\n",
    "my_instruction = \"Summarize in 3 bullet points.\"\n",
    "papers_text = \"\"\n",
    "for p in results['papers']:\n",
    "    t = p['title']\n",
    "    c = p['content'][:200]\n",
    "    papers_text += f'- {t}: {c}...\n'\n",
    "graph_text = \"\"\n",
    "for link in results['graph_links']:\n",
    "    n1 = link['node1']\n",
    "    n2 = link['node2']\n",
    "    graph_text += f'- {n1} causes {n2}\n'\n",
    "custom_prompt = f\"ROLE: {my_role}\nQUESTION: {query}\n\nDATA:\n{papers_text}\n{graph_text}\n\nDO: {my_instruction}\"\n",
    "print(\"Custom prompt created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Bonus: Swap the Brain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Download Test Brain\n",
    "!wget -q https://github.com/nunezmatias/grafoRag/raw/main/examples/test_brain.zip\n",
    "!unzip -o -q test_brain.zip\n",
    "\n",
    "# 2. Initialize a NEW Engine\n",
    "solar_engine = GraphRAGEngine(\n",
    "    vector_db_path='./test_brain/test_db',\n",
    "    graph_json_path='./test_brain/test_skeleton.json'\n",
    ")\n",
    "\n",
    "# 3. Run Query\n",
    "solar_query = 'How does solar energy affect the grid stability?'\n",
    "solar_results = solar_engine.search(solar_query, top_k=2)\n",
    "print(f'Query: {solar_query}')\n",
    "papers_count = len(solar_results['papers'])\n",
    "links_count = len(solar_results['graph_links'])\n",
    "print(f'Found {papers_count} papers and {links_count} links.')\n",
    "if solar_results['graph_links']:\n",
    "    link = solar_results['graph_links'][0]\n",
    "    n1 = link['node1']\n",
    "    n2 = link['node2']\n",
    "    rel = link['relation']\n",
    "    print(f'Link Found: {n1} --[{rel}]--> {n2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced: Load from Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_CUSTOM_GDRIVE_ID = \"1iKcEzECN9LTMi3bIq4ocRfFJgvb1dLus\"\n",
    "try:\n",
    "    drive_engine = GraphRAGEngine(gdrive_id=MY_CUSTOM_GDRIVE_ID)\n",
    "    print('Custom Brain Loaded')\n",
    "    solar_query = 'How does solar energy affect the grid stability?'\n",
    "    drive_results = drive_engine.search(solar_query, top_k=2)\n",
    "    print(f'Query: {solar_query}')\n",
    "    papers_count = len(drive_results['papers'])\n",
    "    links_count = len(drive_results['graph_links'])\n",
    "    print(f'Found {papers_count} papers and {links_count} links.')\n",
    "    if drive_results['graph_links']:\n",
    "        link = drive_results['graph_links'][0]\n",
    "        n1 = link['node1']\n",
    "        n2 = link['node2']\n",
    "        rel = link['relation']\n",
    "        print(f'Link Found: {n1} --[{rel}]--> {n2}')\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}